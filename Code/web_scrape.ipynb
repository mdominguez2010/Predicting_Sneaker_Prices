{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Sneaker Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-10T16:38:01.929762Z",
     "start_time": "2020-10-10T16:38:00.697619Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time, os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T21:27:26.522471Z",
     "start_time": "2020-10-03T21:27:26.070994Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scrape some data (start off small)\n",
    "\n",
    "url = 'https://stockx.com/air-jordan-11-retro-playoffs-2019' \n",
    "\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-03T21:27:27.267310Z",
     "start_time": "2020-10-03T21:27:27.263603Z"
    }
   },
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What status code 403 means per Wikipedia: \"The request contained valid data and was understood by the server, but the server is refusing action. This may be due to the user not having the necessary permissions for a resource or needing an account of some sort, or attempting a prohibited action (e.g. creating a duplicate record where only one is allowed).\"\n",
    "\n",
    "update: Using User-agent works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating list of shoe names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T03:29:39.527092Z",
     "start_time": "2020-10-05T03:29:12.668147Z"
    }
   },
   "outputs": [],
   "source": [
    "page_list = list(range(1,7))\n",
    "shoes_list=[]\n",
    "\n",
    "for page in page_list:\n",
    "    \n",
    "    # Get URL into a BeautifulSoup object\n",
    "    user_agent = {'User-Agent': 'Mozilla/5.0 (Linux; Android 5.1.1; SM-G928X Build/LMY47X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.83 Mobile Safari/537.36'}\n",
    "    url = 'https://stockx.com/retro-jordans?size_types=women&page={}'.format(page)\n",
    "    response  = requests.get(url, headers = user_agent)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    \n",
    "    # Generate list\n",
    "    current_shoes_list=[]\n",
    "    for link in soup.find_all('a'):\n",
    "        current_shoes_list.append(link.get('href'))\n",
    "    \n",
    "    # Focus on the shoe names\n",
    "    shoes_list.extend(current_shoes_list[26:64])\n",
    "    \n",
    "    # Pause\n",
    "    time.sleep(3+2*random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T03:29:48.538242Z",
     "start_time": "2020-10-05T03:29:48.532458Z"
    }
   },
   "outputs": [],
   "source": [
    "shoes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T03:29:52.273685Z",
     "start_time": "2020-10-05T03:29:52.270149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save as Pickle\n",
    "with open('shoes.pickle', 'wb') as to_write:\n",
    "    pickle.dump(shoes_list, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T04:25:48.321564Z",
     "start_time": "2020-10-05T04:25:48.318642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read Pickle and assign once again to variable shoes_list\n",
    "with open('shoes.pickle','rb') as read_file:\n",
    "    shoes_list = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T04:26:06.191170Z",
     "start_time": "2020-10-05T04:26:06.188768Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shoes_list = shoes_list[153:228]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T04:26:07.093541Z",
     "start_time": "2020-10-05T04:26:07.090080Z"
    }
   },
   "outputs": [],
   "source": [
    "len(shoes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through our list of shoe names, scraping data, and adding to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T17:10:39.812475Z",
     "start_time": "2020-10-04T17:10:39.809775Z"
    }
   },
   "outputs": [],
   "source": [
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T04:26:22.178908Z",
     "start_time": "2020-10-05T04:26:17.575349Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_paths=[1] \n",
    "sale_list=[]\n",
    "v_list=[]\n",
    "high_low=[]\n",
    "trade_range=[]\n",
    "twelve_list=[]\n",
    "size_list=[]\n",
    "price_list=[]\n",
    "sale_date_list=[]\n",
    "n_sales=[]\n",
    "price_premium=[]\n",
    "avg_price=[]\n",
    "\n",
    "for shoe in range(len(shoes_list)):\n",
    "    \n",
    "    shoe_type = shoes_list[shoe]\n",
    "    \n",
    "    # Get URL into a BeautifulSoup object\n",
    "    user_agent = {'User-Agent': 'Mozilla/5.0 (Linux; Android 5.1.1; SM-G928X Build/LMY47X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.83 Mobile Safari/537.36'}\n",
    "    url = 'https://stockx.com' + shoe_type\n",
    "    response  = requests.get(url, headers = user_agent)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    \n",
    "      # Open url in chrome\n",
    "#     driver = webdriver.Chrome(chromedriver) \n",
    "#     time.sleep(3+1*random.random())\n",
    "#     driver.get('https://stockx.com' + shoe_type)\n",
    "#     time.sleep(3+2*random.random())  #pause to be sure page has loaded\n",
    "\n",
    "    \n",
    "    # click size drop-down menu\n",
    "#     drop_down = driver.find_element_by_link_text('All')\n",
    "#     time.sleep(1+2*random.random())\n",
    "#     drop_down.click()\n",
    "#     time.sleep(1+2*random.random())\n",
    "\n",
    "    # click size\n",
    "#     click_size = driver.find_element_by_xpath('//*[@id=\"menuitem-{}\"]'.format(num))\n",
    "#     time.sleep(1+2*random.random())\n",
    "#     click_size.click()\n",
    "#     time.sleep(1+2*random.random())\n",
    "\n",
    "#     soup = BeautifulSoup(driver.page_source)\n",
    "#     time.sleep(1+2*random.random())\n",
    "    \n",
    "    # Find 52-week high low data and put it in a list\n",
    "    #high = soup.find_all(class_='value-container')[0].text\n",
    "    try:\n",
    "        high_low = soup.find_all(class_='value-container')[0].text\n",
    "    except:\n",
    "        high_low = np.nan\n",
    "    time.sleep(2+2*random.random())\n",
    "    \n",
    "    # Find trade range and put it in a liast\n",
    "    #trade = soup.find_all(class_='ds-range value-container')[0].text\n",
    "    try:\n",
    "        trade_range = soup.find_all(class_='ds-range value-container')[0].text\n",
    "    except:\n",
    "        trade_range = np.nan\n",
    "    time.sleep(2+1*random.random())\n",
    "    \n",
    "    # Find volatility and put in list\n",
    "    volatility = soup.find_all(class_='value')[-1].text\n",
    "    try:\n",
    "        v_list = volatility\n",
    "    except:\n",
    "        v_list = np.nan\n",
    "    \n",
    "    # Find 12-month rolling data and put it in separate lists\n",
    "    twelve = soup.find_all(class_='gauge-value')\n",
    "    current_twelve = [twelve.text for twelve in twelve]\n",
    "    try:\n",
    "        n_sales = current_twelve[0]\n",
    "    except:\n",
    "        n_sales = np.nan\n",
    "    try:\n",
    "        price_premium = current_twelve[1]\n",
    "    except:\n",
    "        price_premium = np.nan\n",
    "    try:        \n",
    "        avg_price = current_twelve[2]\n",
    "    except:\n",
    "        avg_price = np.nan\n",
    "        \n",
    "    time.sleep(2+3*random.random())\n",
    "   \n",
    "    # click View All Sales\n",
    "#     view_all = driver.find_element_by_link_text('View All Sales')\n",
    "#     view_all.click()\n",
    "#     time.sleep(1+3*random.random())\n",
    "\n",
    "    # Instantiate BeautifulSoup with Chrome above chrome driver\n",
    "#     soup = BeautifulSoup(driver.page_source)\n",
    "#     time.sleep(1+3*random.random())\n",
    "    \n",
    "    # Find our table\n",
    "#     table = soup.find('table')\n",
    "\n",
    "    # Get the rows and put them in a list\n",
    "#     rows = [row.text for row in table.find_all('td')]\n",
    "\n",
    "    # Make list for sizes\n",
    "#     size_list = rows[0]\n",
    "    \n",
    "    # Make list for sizes\n",
    "    size_list = soup.find('span', class_='bid-ask-sizes').text\n",
    "\n",
    "    # Make list for sale price\n",
    "    price_list = soup.find('div', class_='sale-value').text\n",
    "\n",
    "    # Make list for sale prices\n",
    "    sale_date_list = np.nan\n",
    "    \n",
    "    # Create list of names of the current shoe name so it can be added to df\n",
    "    name_list = [shoe_type for i in range(len(x_paths))]\n",
    "\n",
    "    # Find retail price\n",
    "    try:\n",
    "        retail = soup.find(text='Retail Price').findNext().text\n",
    "    except:\n",
    "        retail = np.nan\n",
    "    # Remove white space\n",
    "    try:\n",
    "        retail = \"\".join(retail.split())\n",
    "    except:\n",
    "        retail = np.nan\n",
    "    # Make List\n",
    "    retail_list = [retail for i in range(len(x_paths))]\n",
    "\n",
    "    # Find release date\n",
    "    try:\n",
    "        release = soup.find(text='Release Date').findNext().text\n",
    "    except:\n",
    "        release = np.nan\n",
    "    # Remove white space\n",
    "    try:\n",
    "        release = \"\".join(release.split())\n",
    "    except:\n",
    "        release = np.nan\n",
    "    try:    \n",
    "        release_list = [release for i in range(len(x_paths))]\n",
    "    except:\n",
    "        release_list = np.nan\n",
    "\n",
    "    # Dataframe\n",
    "    d = {'Name': name_list, 'Release Date': release_list, 'Retail Price': retail_list, 'Sale Price': price_list, 'Size': size_list, 'Sale Date': sale_date_list,\n",
    "         '52wk High|Low': high_low, '12mo Trade Range': trade_range, 'Volatility': v_list, '# of Sales': n_sales,\n",
    "         'Price Premium': price_premium, 'Avg Resale Price': avg_price}\n",
    "    df_current = pd.DataFrame(data=d)\n",
    "    df = pd.concat([df, df_current], ignore_index=True) # READ CSV INTO JUPYTER NOTEBOOK BEFORE RUNNING THIS LOOP\n",
    "    \n",
    "    # pause\n",
    "    time.sleep(10+2*random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T04:26:57.929299Z",
     "start_time": "2020-10-05T04:26:57.919946Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save 'df' to csv\n",
    "df.to_csv(r'/Users/dominguez/Documents/onl20_ds4/curriculum/project-02/df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T02:33:20.883810Z",
     "start_time": "2020-10-06T02:33:20.852601Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the CSV and assign to 'df'\n",
    "df = pd.read_csv('df.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:56:31.196494Z",
     "start_time": "2020-10-05T19:56:31.183066Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T19:56:32.927018Z",
     "start_time": "2020-10-05T19:56:32.923444Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T15:02:53.158520Z",
     "start_time": "2020-10-05T15:02:53.103374Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T15:13:35.608732Z",
     "start_time": "2020-10-05T15:13:35.604597Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All objects! :-("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column for brand names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:04:59.905096Z",
     "start_time": "2020-10-05T22:04:59.901445Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Name'] = df['Name'].str.replace('/','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:05:01.399372Z",
     "start_time": "2020-10-05T22:05:01.396218Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Brand'] = df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:05:02.562957Z",
     "start_time": "2020-10-05T22:05:02.465836Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(df['Brand'])):\n",
    "    if 'jordan' in df['Brand'][i]:\n",
    "        df['Brand'][i] = 'Jordan'\n",
    "    elif 'nike' in df['Name'][i]:\n",
    "        df['Brand'][i] = 'Nike'\n",
    "    elif 'adidas' in df['Name'][i]:\n",
    "        df['Brand'][i] = 'Adidas'\n",
    "    else:\n",
    "        df['Brand'][i] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:05:03.605948Z",
     "start_time": "2020-10-05T22:05:03.592339Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-arrange columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:07:17.004190Z",
     "start_time": "2020-10-05T22:07:16.988289Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[['Name','Brand','Release Date','Retail Price','Sale Price','Size','Sale Date','52wk High|Low',\n",
    "         '12mo Trade Range','Volatility','# of Sales','Price Premium','Avg Resale Price']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T21:27:59.581051Z",
     "start_time": "2020-10-05T21:27:59.575452Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_price_by_brand = df.groupby(['Brand'])[['Sale Price']].mean().reset_index()\n",
    "#plt.bar(df.Brand, df['Sale Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T21:33:12.991762Z",
     "start_time": "2020-10-05T21:33:12.868996Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(avg_price_by_brand['Brand'], avg_price_by_brand['Sale Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Sale Price to int \\\n",
    "',' and '$' were removed and the '--' were converted to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:07:39.842326Z",
     "start_time": "2020-10-05T22:07:39.836309Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Sale Price\"] = df['Sale Price'] \\\n",
    "    .str.replace(',','').str.replace('$','').str.replace('--','0').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:07:41.463974Z",
     "start_time": "2020-10-05T22:07:41.457502Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Sale Price\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix # of Sales column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace '--' with a small number, since a '--' likely means there wasn't much data to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:07:43.270074Z",
     "start_time": "2020-10-05T22:07:43.265771Z"
    }
   },
   "outputs": [],
   "source": [
    "df['# of Sales'] = df['# of Sales'].str.replace('--','100').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:07:44.015868Z",
     "start_time": "2020-10-05T22:07:44.009581Z"
    }
   },
   "outputs": [],
   "source": [
    "df['# of Sales'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix Size column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove '%', replace '--' with small volatility since those shoes with '--' likely had little activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:07:47.388404Z",
     "start_time": "2020-10-05T22:07:47.383182Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Volatility'] = df['Volatility'].str.replace('%','').str.replace('--','2.0').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:07:48.032711Z",
     "start_time": "2020-10-05T22:07:48.026194Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Volatility'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:07:51.129981Z",
     "start_time": "2020-10-05T22:07:49.651000Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# You can configure the format of the images: ‘png’, ‘retina’, ‘jpeg’, ‘svg’, ‘pdf’.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "# this statement allows the visuals to render within your Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "plt.bar(df['Volatility'], df['Sale Price']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:07:53.049484Z",
     "start_time": "2020-10-05T22:07:52.900858Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['# of Sales'], df['Sale Price']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T15:10:26.282249Z",
     "start_time": "2020-10-05T15:10:26.276993Z"
    }
   },
   "source": [
    "Let's get some datetime columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:07:56.502269Z",
     "start_time": "2020-10-05T22:07:56.497881Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Release Date'] = pd.to_datetime(df['Release Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be quite a bit of NaN values for Sale Date, let's take a closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T18:21:52.451812Z",
     "start_time": "2020-10-05T18:21:52.446620Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Sale Date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the Sale Date values are for 10/3. In other words, most of the sale date datapoints represent recent purchases\n",
    "\n",
    "Let's fill the NaN values with current purchases data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:10:06.906009Z",
     "start_time": "2020-10-05T22:10:06.903108Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Sale Date'].fillna('Saturday, October 3, 2020', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:10:09.404430Z",
     "start_time": "2020-10-05T22:10:09.399154Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Sale Date'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many NaNs do we have in this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:10:48.519338Z",
     "start_time": "2020-10-05T22:10:48.515066Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Sale Date'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:11:33.466216Z",
     "start_time": "2020-10-05T22:11:33.449884Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:18:06.876571Z",
     "start_time": "2020-10-05T22:18:06.872351Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:20:51.916533Z",
     "start_time": "2020-10-05T22:20:51.912460Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save as Pickle\n",
    "with open('df.pickle', 'wb') as to_write:\n",
    "    pickle.dump(df, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:49:32.060413Z",
     "start_time": "2020-10-05T22:49:32.055966Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read Pickle and assign once again to variable shoes_list\n",
    "with open('df.pickle','rb') as read_file:\n",
    "    df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:49:32.801088Z",
     "start_time": "2020-10-05T22:49:32.787419Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:49:34.713924Z",
     "start_time": "2020-10-05T22:49:34.710114Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new = df[['Name','Sale Price','Brand','Release Date','Sale Date','# of Sales','Volatility','Price Premium']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:49:35.554436Z",
     "start_time": "2020-10-05T22:49:35.544113Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:28:45.852524Z",
     "start_time": "2020-10-05T22:28:45.847824Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price Premium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:49:41.158777Z",
     "start_time": "2020-10-05T22:49:41.152657Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_new['Price Premium'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace '--' with 1%. After reviewing some shoes with '--' values, it was determined these shoes do not resale\n",
    "as often as more mainstream shoes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:49:43.470513Z",
     "start_time": "2020-10-05T22:49:43.463567Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new['Price Premium'] = df_new['Price Premium'].str.replace(',','') \\\n",
    "    .str.replace('$','').str.replace('%','').str.replace('--','1.0').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:49:45.527160Z",
     "start_time": "2020-10-05T22:49:45.509139Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 'Days from Release' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Sale Date' column needs to be converted to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:51:24.655146Z",
     "start_time": "2020-10-05T22:51:24.650392Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new['Sale Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:53:00.575826Z",
     "start_time": "2020-10-05T22:53:00.569071Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new['Sale Date'] = pd.to_datetime(df_new['Sale Date']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:53:39.982568Z",
     "start_time": "2020-10-05T22:53:39.978198Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:58:11.518210Z",
     "start_time": "2020-10-05T22:58:11.514297Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new['Days from Release'] = df_new['Sale Date'] - df_new['Release Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:59:39.153515Z",
     "start_time": "2020-10-05T22:59:39.150657Z"
    }
   },
   "source": [
    "Rearrange columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T23:03:38.460267Z",
     "start_time": "2020-10-05T23:03:38.456607Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new = df_new[['Sale Price','Brand','Release Date','Sale Date','Days from Release','# of Sales','Volatility','Price Premium']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T23:05:48.257294Z",
     "start_time": "2020-10-05T23:05:48.252786Z"
    }
   },
   "source": [
    "### STOPPING POINT, encode categorical  variable 'Brand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T23:07:05.451812Z",
     "start_time": "2020-10-05T23:07:05.441223Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
